---
title: "LINCS analysis with slinky"
author: "Eric J. Kort"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{"LINCS analysis with slinky"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Terminology

The gene expression data derived from a single cell culture well treated with a single perturbagen has historically been referred to as an "instance" in the CMAP/LINCS program.  I will use "instance" in this way.  For any given perturbagen, there will be many instances encompassing different doses, durations, and cell lines as well as technical replicates.  

## Prerequisites

In this vignette we perform some basic analyses using the L1000 data expression data from the LINCS project.  To complete this vignette you will need access to the LINCS Phase I Level 3 data file.  This file may already be available from your local bioinformatics core.  If you need or want to download it yourself, note that the datafile is quite large (~40GB). A robust multithreaded download client makes this much faster and less prone to failures due to connectivity hiccups.  For example, you might try:

```{r, engine = 'bash', eval=FALSE}
aria2c -x 8 -s 8 https://goo.gl/3TigFI
gzip -d *.gz
```

Details on the LINCS data files are available here: https://docs.google.com/document/d/1q2gciWRhVCAAnlvF2iRLuJ7whrGP6QjpsCMq1yWz7dU

Secondly, access to the LINCS api and clue.io requires a user key, which can be obtained from the LINCS by registering at https://clue.io (free for non-commercial use).  You can provide your key directly in the call to `Slinky$new("your_key_here")`, or define the environment variable `CLUE_API_KEY` and set it to your key.

## Data selection

It is typically desirable to identify a subset of the L1000 data for analysis.  For our first example, let us identify those instances treated with FDA approved compounds that are part of the "gold" subset of highly consistent instances (as defined by LINCS).  We will further restrict our analysis to the 978 genes directly measured by the LINCS project (i.e. we will exclude the extrapolated data).  Definitively identifying FDA approved drugs is a little tricky due to subtle (and not so subtle) differences in vocabularies, but we exploit the "repositioning" data available at the `rep_drugs` endpoint to achieve our ends. 


```{r, echo=FALSE, message=F, warning=F, eval=FALSE}
library(slinky)

#update following lines with your details:
key <- "YOUR_API_KEY"
gctx <- "/path/to/GSE92742_Broad_LINCS_Level3_INF_mlr12k_n1319138x12328.gctx"

sl <- Slinky$new(key, gctx)
fda <- sl$clue("rep_drugs", where_clause=list("status_source"=list(like = "FDA Orange"),
                                                   "final_status"="Launched",
                                                   "animal_only"="0",
                                                   "in_cmap"=TRUE),
                                                   verbose=TRUE)

```

With this list of putative FDA approved agents profiled by LINCS in hand, we can now retrieve details about the instances perturbed by these agents.  This call will include all the compound names in a single query.  The resulting query is over 9000 characters.  This is above the limit (at least anecdotally) imposed by some browsers.  However, neither the `httr` client library we are using, nor the clue.io server seem to be bothered by a query this long, and it is certainly more performant (and kinder to the server) than submitting many separate requests.

Related, note `inq` syntax used below to provide an array of possible values to match.  This is a vernacular of the `loopback` framework on which the clue.io service is built.

```{r, eval=FALSE}

fda_pert <- sl$clue.instances(where_clause=list("pert_type"="trt_cp", 
                                                "is_gold"=TRUE,
                                                "pert_iname"=list("inq"=fda$pert_iname)),
                              verbose=TRUE, poscon="omit")

```

## Loading data from gctx file

Now that we know which instances and which genes we are interested in, we are ready to load the landmark gene expression data from the gctx file.  First we shall identify the columns and rows we want to fetch by retrieving the column ids from our gctx file and comparing that to our list of desired ids. For the genes, we know that the first 978 rows of the expression matrix from LINCS contains the landmark genes. 

Fetching the roughly 32,000 x 978 matrix from the gctx file takes a couple of minutes, presumably in part because the columns are not at all contiguous.   If we save the resulting data subset as RDS, it can be loaded in just a couple seconds.  

```{r, eval=FALSE}

ids <- sl$colnames()
col.ix <- which(ids %in% fda_pert)
row.ix <- 1:978

data <- sl$readGCTX(index = list(row.ix, col.ix))

saveRDS(data, compress="gzip", file="l1000_fda.rds")

```

While you can generate the file as shown above, for convenience the resulting RDS file is also available for download from the `locket` repository on github (https://github.com/erikor/locket/raw/master/l1000_fda.rds).  Downloading and loading this datafile takes 11 seconds on our local machine.

```{r, eval=FALSE}
  link <- "https://github.com/erikor/locket/raw/master/l1000_fda.rds"
  temp <- tempfile()
  download.file(link,temp,method = "curl", extra = "-L", quiet=TRUE)
  fda <- readRDS(temp)
  unlink(temp)
```

Next we are going to need access to the vehicle control samples.  We can fetch these in the same was as the treated samples above.  In this example, we will speed up the metadata fetch a bit by parallelization.  Caveat emptor: too much parallelism here might be perceived as obnoxious to the clue.io server.  Note that this is a simplistic approach to idetnifying controls; a better way will be discussed below.

```{r, eval=FALSE}
cl <- parallel::makeCluster(4)
dmso_pert <- sl$clue("profiles", 
                     fields = c("det_plate", "distil_id"), 
                     where_clause=list("pert_type"="ctl_vehicle", 
                                       "pert_id"="DMSO"), cl=cl)
stopCluster(cl)

ids <- sl$colnames()
col.ix <- which(ids %in% dmso_pert$distil_id)
ids <- ids[col.ix]

data <- sl$readGCTX(index = list(1:978, col.ix))
rownames(data) <- genes
colnames(data) <- ids

saveRDS(data, compress="gzip", file="l1000_dmso.rds")
```

Again, by the miracle of television, this file is available via the `locket` github repository.

```{r, eval=FALSE}
  link <- "https://github.com/erikor/locket/raw/master/l1000_dmso.rds"
  temp <- tempfile()
  download.file(link,temp,method = "curl", extra = "-L", quiet=TRUE)
  dmso <- readRDS(temp)
  unlink(temp)
```


## Intelligent vehicles

The above was an admittedly crude approach to identifiying the vehicles associated with our perturbed instances.  It made the assumption that DMSO is the right vehicle for each perturbation, and it also pulled vehicle instances from plates that may not have any of our selected perturbagens on them, which may or may not be what you want.  Our preference is to use only controls from the same plate as the perturbagen in question to reduce batch effects.  The slinky package can intelligently identify the set of controls that corresponds to set of perturbed instances.  Here "appropriate" means same-plate controls that are of the correct type (vector controls for perturbagens of type trt_sh or trt_oe, or the corresponding vehicle for each perturbagen.  For perturbatios of type trt_cp, it does this by querying clue for the vehicle field corresponding to each instance id and then identifying same-plate instances which were treated with that vehicle.  Similarly, same plate instances treated with vector only controls are identified for instances that are of type trt_sh or trt_oe.

Once the applicable control perturbations are identified, the corresponding instance ids are extracted from the info file from GEO.  If that file has not already been obtained, it will be downloaded automatically.

```{r eval=FALSE, include=TRUE}

control_instances <- sl$controls(fda_pert, cl=cl, verbose=TRUE)

```


## Expression Sets

It would be better to have the above datasets annotated with available metadata for further subsetting and analysis.  We can merge the data provided by the metadata file provided by LINCS (GSE92742_Broad_LINCS_inst_info.txt) with expression data from our gctx file into a an ExpressionSet object that will keep things organized.  If you already know what instances you want, you can provide the functions with an ids argument.  Alternatively, you can specify a where_clause to query clue.io to identify the appropriate samples.  

```{r eval=FALSE, include=TRUE}

treated <- sl$clue.instances(where_clause=list("pert_desc"="LMNA", pert_type="trt_sh"))
controls <- sl$controls(treated)$distil_id
ix <- which(sl$colnames() %in% c(treated, controls))
exp <- sl$toEset(ids = ix)

control_instances <- sl$controls(fda_pert, cl=cl, verbose=TRUE)

```

