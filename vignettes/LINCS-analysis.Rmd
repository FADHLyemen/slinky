---
title: "LINCS analysis with slinky"
author: "Eric J. Kort"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{"LINCS analysis with slinky"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

In this vignette we perform some basic analyses using the L1000 data expression data from the LINCS project.  To complete this vignette you will need access to the LINCS Phase I Level 3 data file.  This file may already be available from your local bioinformatics core.  If you need or want to download it yourself, note that the datafile is quite large (~40GB). A robust multithreaded download client makes this much faster and less prone to failures due to connectivity hiccups.  For example, you might try:

```{r, engine = 'bash', eval=FALSE}
aria2c -x 8 -s 8 https://goo.gl/3TigFI
gzip -d *.gz
```

Details on the LINCS data files are available here: https://docs.google.com/document/d/1q2gciWRhVCAAnlvF2iRLuJ7whrGP6QjpsCMq1yWz7dU

Secondly, access to the LINCS api and clue.io requires a user key.  You can provide your key directly in the call to `Slinky$new("your_key_here")`, or define the environment variable `CLUE_API_KEY` and set it to your key.

## Data selection

It is typically desirable to identify a subset of the L1000 data for analysis.  Here we will restrict our analysis to instances treated with FDA approved compounds that are part of the "gold" subset of highly consistent instances (as defined by LINCS).  We will also restrict our analysis to the 978 genes directly measured by the LINCS project (i.e. we will exclude the extrapolated data).  Definitively identifying FDA approved drugs is a little tricky due to subtle (and not so subtle) differences in vocabularies, but we exploit the "repositioning" data available at the `rep_drugs` endpoint to achieve our ends.  Note the "inq" syntax used below.  This is a vernacular of the `loopback` framework on which the clue.io service is built.


```{r, echo=TRUE, eval=FALSE, message=F, warning=F}
library(slinky)
sl <- Slinky$new() # assumes environment variable CLUE_API_KEY is set.
fda <- sl$fetch("rep_drugs", where_clause=list("status_source"=list(like = "FDA Orange"),
                                                   "final_status"="Launched",
                                                   "animal_only"="0",
                                                   "in_cmap"=TRUE))



```

```{r, echo=FALSE, message=F, warning=F}
library(slinky)
user_key <- content(httr::GET("https://api.clue.io/temp_api_key"), as="parsed")$user_key
sl <- Slinky$new(user_key)
fda <- sl$fetch("rep_drugs", where_clause=list("status_source"=list(like = "FDA Orange"),
                                                   "final_status"="Launched",
                                                   "animal_only"="0",
                                                   "in_cmap"=TRUE))



```

With this list of putative FDA approved agents profiled by LINCS in hand, we can now retrieve details about the instances perturbed by these agents.  This call will include all the compound names in a single query.  The resulting query is over 9000 characters.  This is above the limit (at least anecdotally) imposed by some browsers.  However, neither the `httr` client library we are using, nor the clue.io server seem to be bothered by a query this long, and it is certainly more performant than submitting many separate requests.

Related, note `inq` syntax used below to provide an array of possible values to match.  This is a vernacular of the `loopback` framework on which the clue.io service is built.

Finally, note that when multiple values are present for a given field (i.e., the JSON returned by clue.io contained an array of values), these values have been concatenated by the `|` character so that they could be placed in a single column of the dataframe.  Without this concatenation, a well formed `data.frame` could not be reliably returned by `fetch`.

```{r}
fda_pert <- sl$fetch("sigs", 
                     fields = c("pert_desc", "distil_id"), 
                     where_clause=list("pert_type"="trt_cp", 
                                       "is_gold"=TRUE,
                                       "pert_iname"=list("inq"=fda$pert_iname)))

# expand the delimited distil_id values
unwrap <- function(x) {
  ids <- unlist(strsplit(x[1], split = "\\|"))
  res <- cbind(x[2], ids)
  colnames(res) <- c("pert_desc", "distil_id")
  return(res)
}

#inst_fda_gold <- unique(unlist(strsplit(fda_pert$distil_id, split = "\\|")))
inst_fda_gold <- do.call(rbind, apply(fda_pert, 1, unwrap))
rownames(inst_fda_gold) <- NULL

```

Finally, we can get a list of the 978 landmark genes from the genes endpoint:

```{r}
l1000 <- sl$fetch("genes", fields=c("entrez_id", "gene_symbol"), where_clause=list("l1000_type" = "landmark"))

```

## Loading data from gctx file

Now that we know which instances and which genes we are interested in, we are ready to load the landmark gene expression data from the gctx file.  First we shall identify the columns and rows we want to fetch.  Here we assume the level 3 data is saved in the directory `~/lincs_data`.  Fetching the roughly 32,000 x 1000 matrix from the gctx file takes a couple of minutes, presumably in part because the columns are not at all contiguous.   If we save the resulting data subset as RDS, it can be loaded in just a couple seconds.  

```{r eval=FALSE}
gctx.file <- "~/lincs_data/GSE92742_Broad_LINCS_Level3_INF_mlr12k_n1319138x12328.gctx"

ids <- sl$gctx.colnames(gctx.file)
col.ix <- which(ids %in% inst_fda_gold$distil_id)
ids <- ids[col.ix]

genes <- sl$gctx.rownames(gctx.file)
row.ix <- which(genes %in% l1000$entrez_id) # it's the first 978 genes in the data matrix!
genes <- genes[row.ix]

data <- sl$gctx.read(gctx.file, index = list(row.ix, col.ix))
rownames(data) <- genes
colnames(data) <- ids
saveRDS(data, compress="gzip", file="l1000_fda.rds")

```

While you can generate the file as shown above, for convenience the resulting RDS file is also available for download from the `locket` repository on github (https://github.com/erikor/locket/raw/master/l1000_fda.rds).  Downloading and loading this datafile takes 11 seconds on my system.

```{r}
  link <- "https://github.com/erikor/locket/raw/master/l1000_fda.rds"
  temp <- tempfile()
  download.file(link,temp,method = "curl", extra = "-L", quiet=TRUE)
  fda <- readRDS(temp)
  unlink(temp)
```

Next we are going to need access to the vehicle control samples.  We can fetch these in the same was as the treated samples above.  In this example, we will speed up the metadata fetch a bit by parallelization.

```{r eval=FALSE}
cl <- makeCluster(8)
dmso_pert <- sl$fetch("profiles", 
                     fields = c("det_plate", "distil_id"), 
                     where_clause=list("pert_type"="ctl_vehicle", 
                                       "pert_id"="DMSO"), cl=cl)
stopCluster(cl)

ids <- sl$gctx.colnames(gctx.file)
col.ix <- which(ids %in% dmso_pert$distil_id)
ids <- ids[col.ix]

data <- sl$gctx.read(gctx.file, index = list(row.ix, col.ix))
rownames(data) <- genes
colnames(data) <- ids

saveRDS(data, compress="gzip", file="l1000_dmso.rds")
```

Again, by the miracle of television, this file is available via the `locket` github repository.

```{r}
  link <- "https://github.com/erikor/locket/raw/master/l1000_dmso.rds"
  temp <- tempfile()
  download.file(link,temp,method = "curl", extra = "-L", quiet=TRUE)
  dmso <- readRDS(temp)
  unlink(temp)
```

Now we have the pieces we need to calculate robust z-scores for each instance in our fda dataset vs. same-plate vehicle control.

```{r, eval=FALSE, echo=TRUE}
library("doParallel")
plates <- gsub(":.*", "", colnames(dmso))
ctrl <- t(apply(dmso, 1, function(x) { tapply(x, INDEX = plates, mean)}))

cl<-makeCluster(8)
registerDoParallel(cl)
zs <- foreach(i = 1:ncol(fda), .combine = cbind) %dopar% {
  plate <- gsub(":.*", "", colnames(fda)[i])
  fc <- fda[,i] / ctrl[,plate]
  (fc - median(fc)) / mad(fc)
}
stopCluster(cl)
colnames(zs) <- colnames(fda)
rownames(zs) <- rownames(fda)
zs <- zs * 1000 # save space on github
saveRDS(zs, file="l1000_fda_zsvc_x1000.rds", compress="gzip")

```

Again, this file is available via the `locket` github repository.

## Gene set enrichment

Signatures of up- and down-regulated genes related to some perturbation or phenotype of interest can be scored against expression data using the `slinky` package.  (A future revision will describe approaches to defining such signatures out of the LINCS data itself).  Below is a trivial example of generating a gene signature and then scoring it against a tiny set of test data (the first 50 columns of the FDA zscore data from above), using two different enrichment statistics (the connectivity core of Lamb et al. as used by the original CMAP project, and the XSUM statistic described by Agarwal et al.)

```{r}

zsvc <- system.file("extdata", "test_inst_zsvc_x1000.rds", package="slinky")
info <- system.file("extdata", "test_inst_info.rds", package="slinky")
data <- readRDS(zsvc) / 1000
up <- rownames(data)[order(data[,1], decreasing = TRUE)][1:25]
down <- rownames(data)[order(data[,1])][1:25]
cs <- sl$score(data, "ks", up=up, down=down)
xs <- sl$score(data, "xsum", up=up, down=down)
plot(cs, xs, pch=19)
```
